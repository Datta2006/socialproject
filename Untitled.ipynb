{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c2add2a-0179-4ee9-8e21-80ae25816bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter is working\n"
     ]
    }
   ],
   "source": [
    "print(\"Jupyter is working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca13e98-530d-4386-a81a-aed8bd612007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love this!\n",
      "This is bad.\n",
      "Today is amazing!\n",
      "I hate everything.\n",
      "This project is fun.\n"
     ]
    }
   ],
   "source": [
    "sample_posts = [\n",
    "    \"I love this!\",\n",
    "    \"This is bad.\",\n",
    "    \"Today is amazing!\",\n",
    "    \"I hate everything.\",\n",
    "    \"This project is fun.\"\n",
    "]\n",
    "\n",
    "for post in sample_posts:\n",
    "    print(post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01a9d6a8-1eee-4b65-9d0c-0f0379498e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: I love this!\n",
      "cleaned : i love this\n",
      "---\n",
      "original: This is bad.\n",
      "cleaned : this is bad\n",
      "---\n",
      "original: Today is amazing!\n",
      "cleaned : today is amazing\n",
      "---\n",
      "original: I hate everything.\n",
      "cleaned : i hate everything\n",
      "---\n",
      "original: This project is fun.\n",
      "cleaned : this project is fun\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean(text):\n",
    "    text = text.lower()                      # lowercase\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)      # remove links\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)     # keep only letters/spaces\n",
    "    return text.strip()\n",
    "\n",
    "for post in sample_posts:\n",
    "    print(\"original:\", post)\n",
    "    print(\"cleaned :\", clean(post))\n",
    "    print(\"---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18b192f6-54aa-42cd-b166-47a002535f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (5, 10)\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.83088075 0.         0.55645052 0.        ]\n",
      " [0.         0.72604443 0.         0.         0.         0.48624042\n",
      "  0.         0.         0.48624042 0.        ]\n",
      " [0.63907044 0.         0.         0.         0.         0.42799292\n",
      "  0.         0.         0.         0.63907044]\n",
      " [0.         0.         0.70710678 0.         0.70710678 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.58752141 0.         0.39346994\n",
      "  0.         0.58752141 0.39346994 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Clean all posts first\n",
    "cleaned_posts = [clean(p) for p in sample_posts]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(cleaned_posts)\n",
    "\n",
    "print(\"Shape:\", vectors.shape)\n",
    "print(vectors.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f16241c-cbed-4915-85c2-ea114fabeab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fake labels for our tiny example\n",
    "# 1 = positive, 0 = negative\n",
    "labels = [1, 0, 1, 0, 1]  \n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(vectors, labels)\n",
    "\n",
    "print(\"Model trained!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a074cfc-aacf-42ef-8648-1840031f5cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1]\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"I am very happy today!\"]\n",
    "\n",
    "# clean it\n",
    "cleaned_new = [clean(t) for t in new_text]\n",
    "\n",
    "# convert to numbers\n",
    "vec_new = vectorizer.transform(cleaned_new)\n",
    "\n",
    "# predict\n",
    "prediction = model.predict(vec_new)\n",
    "\n",
    "print(\"Prediction:\", prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d669888-a05b-41bf-898c-a82b6364b7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text):\n",
    "    cleaned = clean(text)\n",
    "    vec = vectorizer.transform([cleaned])\n",
    "    pred = model.predict(vec)[0]\n",
    "    return \"positive\" if pred == 1 else \"negative\"\n",
    "\n",
    "print(predict_sentiment(\"I love this project!\"))\n",
    "print(predict_sentiment(\"This is terrible\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee3bd2f8-1484-47d9-9561-44ced4f96568",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/training.1600000.processed.noemoticon.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/training.1600000.processed.noemoticon.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# load only first 10000 rows to keep it fast\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Sentiment140 format: columns -> [target, id, date, flag, user, text]\u001b[39;00m\n\u001b[1;32m     10\u001b[0m df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m5\u001b[39m]]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/training.1600000.processed.noemoticon.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Change filename if your file is named differently and is inside social-project/data/\n",
    "csv_path = \"data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "# load only first 10000 rows to keep it fast\n",
    "df = pd.read_csv(csv_path, encoding='latin-1', header=None, nrows=10000)\n",
    "\n",
    "# Sentiment140 format: columns -> [target, id, date, flag, user, text]\n",
    "df = df[[0,5]]\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "# Convert labels (Sentiment140 uses 0=negative, 4=positive) -> convert to 0/1\n",
    "df['label'] = df['label'].apply(lambda x: 1 if x==4 else 0)\n",
    "\n",
    "# quick inspect\n",
    "print(\"Rows:\", len(df))\n",
    "print(df['label'].value_counts())\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d41f8bd6-766a-4f15-a824-6a3703a990fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['notes.txt',\n",
       " 'anaconda_projects',\n",
       " 'Untitled.ipynb',\n",
       " 'test.py',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a93d9c4-fe17-4d30-aea6-762be6f6af70",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/training.1600000.processed.noemoticon.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/training.1600000.processed.noemoticon.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# load only first 10000 rows to keep it fast\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Sentiment140 format: columns -> [target, id, date, flag, user, text]\u001b[39;00m\n\u001b[1;32m     10\u001b[0m df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m5\u001b[39m]]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/training.1600000.processed.noemoticon.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Change filename if your file is named differently and is inside social-project/data/\n",
    "csv_path = \"data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "# load only first 10000 rows to keep it fast\n",
    "df = pd.read_csv(csv_path, encoding='latin-1', header=None, nrows=10000)\n",
    "\n",
    "# Sentiment140 format: columns -> [target, id, date, flag, user, text]\n",
    "df = df[[0,5]]\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "# Convert labels (Sentiment140 uses 0=negative, 4=positive) -> convert to 0/1\n",
    "df['label'] = df['label'].apply(lambda x: 1 if x==4 else 0)\n",
    "\n",
    "# quick inspect\n",
    "print(\"Rows:\", len(df))\n",
    "print(df['label'].value_counts())\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b5c494-d14e-42cb-b01b-2158aade265c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b012596-cf97-4246-8c4e-b3305e4309d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['notes.txt',\n",
       " 'anaconda_projects',\n",
       " 'Untitled.ipynb',\n",
       " 'test.py',\n",
       " '.ipynb_checkpoints',\n",
       " 'data']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cec40d5e-c9a5-435d-9677-22edbd67feba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 10000\n",
      "label\n",
      "0    10000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1      0  is upset that he can't update his Facebook by ...\n",
       "2      0  @Kenichan I dived many times for the ball. Man...\n",
       "3      0    my whole body feels itchy and like its on fire \n",
       "4      0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Change filename if your file is named differently and is inside social-project/data/\n",
    "csv_path = \"data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "# load only first 10000 rows to keep it fast\n",
    "df = pd.read_csv(csv_path, encoding='latin-1', header=None, nrows=10000)\n",
    "\n",
    "# Sentiment140 format: columns -> [target, id, date, flag, user, text]\n",
    "df = df[[0,5]]\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "# Convert labels (Sentiment140 uses 0=negative, 4=positive) -> convert to 0/1\n",
    "df['label'] = df['label'].apply(lambda x: 1 if x==4 else 0)\n",
    "\n",
    "# quick inspect\n",
    "print(\"Rows:\", len(df))\n",
    "print(df['label'].value_counts())\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38fc7532-f2df-4bd8-a80f-e6b4f45fa353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows: 100000\n",
      "Raw label value counts:\n",
      "0\n",
      "0    100000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample rows (first 10):\n",
      "   0           1                             2         3                4  \\\n",
      "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
      "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
      "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
      "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
      "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
      "5  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY         joy_wolf   \n",
      "6  0  1467811592  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY          mybirch   \n",
      "7  0  1467811594  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY             coZZ   \n",
      "8  0  1467811795  Mon Apr 06 22:20:05 PDT 2009  NO_QUERY  2Hood4Hollywood   \n",
      "9  0  1467812025  Mon Apr 06 22:20:09 PDT 2009  NO_QUERY          mimismo   \n",
      "\n",
      "                                                   5  \n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1  is upset that he can't update his Facebook by ...  \n",
      "2  @Kenichan I dived many times for the ball. Man...  \n",
      "3    my whole body feels itchy and like its on fire   \n",
      "4  @nationwideclass no, it's not behaving at all....  \n",
      "5                      @Kwesidei not the whole crew   \n",
      "6                                        Need a hug   \n",
      "7  @LOLTrish hey  long time no see! Yes.. Rains a...  \n",
      "8               @Tatiana_K nope they didn't have it   \n",
      "9                          @twittera que me muera ?   \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = \"data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "# load first 100k rows (fast enough) and inspect raw label values\n",
    "raw = pd.read_csv(csv_path, encoding='latin-1', header=None, usecols=[0], nrows=100000)\n",
    "print(\"Loaded rows:\", len(raw))\n",
    "print(\"Raw label value counts:\")\n",
    "print(raw[0].value_counts())\n",
    "\n",
    "# show the first 10 rows for a quick look\n",
    "raw_full = pd.read_csv(csv_path, encoding='latin-1', header=None, nrows=10)\n",
    "print(\"\\nSample rows (first 10):\")\n",
    "print(raw_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e612ab7a-9363-4d26-b628-751aec478dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    10000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i cant sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@alba17 Sorry about kid situation. Good luck w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>nhá» nhÃ  quÃ¡!!! cá»© má»i láº§n nghe bÃ i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Missing Him!! Twitter Me RED?? What the heck i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>#musicmonday i got the blues today     ***sad ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0                                      i cant sleep \n",
       "1      0  @alba17 Sorry about kid situation. Good luck w...\n",
       "2      0  nhá» nhÃ  quÃ¡!!! cá»© má»i láº§n nghe bÃ i ...\n",
       "3      0  Missing Him!! Twitter Me RED?? What the heck i...\n",
       "4      0  #musicmonday i got the blues today     ***sad ..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = \"data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "# load rows 500,000 to 510,000 (a slice with mixed sentiment)\n",
    "df_mixed = pd.read_csv(\n",
    "    csv_path,\n",
    "    encoding='latin-1',\n",
    "    header=None,\n",
    "    skiprows=500000,\n",
    "    nrows=10000\n",
    ")\n",
    "\n",
    "df_mixed = df_mixed[[0,5]]\n",
    "df_mixed.columns = [\"label\", \"text\"]\n",
    "\n",
    "print(df_mixed['label'].value_counts())\n",
    "df_mixed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d79d817-997e-42ee-a060-26bd188d2a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    10000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mixed['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0813e47-8ed9-4ca2-8c46-cb91ec952ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2401  Borderlands  Positive  \\\n",
      "0  2401  Borderlands  Positive   \n",
      "1  2401  Borderlands  Positive   \n",
      "2  2401  Borderlands  Positive   \n",
      "3  2401  Borderlands  Positive   \n",
      "4  2401  Borderlands  Positive   \n",
      "\n",
      "  im getting on borderlands and i will murder you all ,  \n",
      "0  I am coming to the borders and I will kill you...     \n",
      "1  im getting on borderlands and i will kill you ...     \n",
      "2  im coming on borderlands and i will murder you...     \n",
      "3  im getting on borderlands 2 and i will murder ...     \n",
      "4  im getting into borderlands and i can murder y...     \n",
      "Index(['2401', 'Borderlands', 'Positive',\n",
      "       'im getting on borderlands and i will murder you all ,'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/twitter_training.csv\")\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f1e9df6-4a51-4ed3-bea5-b98b9eb5005f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id        topic     label  \\\n",
      "0  2401  Borderlands  Positive   \n",
      "1  2401  Borderlands  Positive   \n",
      "2  2401  Borderlands  Positive   \n",
      "3  2401  Borderlands  Positive   \n",
      "4  2401  Borderlands  Positive   \n",
      "\n",
      "                                                text  \n",
      "0  im getting on borderlands and i will murder yo...  \n",
      "1  I am coming to the borders and I will kill you...  \n",
      "2  im getting on borderlands and i will kill you ...  \n",
      "3  im coming on borderlands and i will murder you...  \n",
      "4  im getting on borderlands 2 and i will murder ...  \n",
      "label\n",
      "Negative      22542\n",
      "Positive      20832\n",
      "Neutral       18318\n",
      "Irrelevant    12990\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"data/twitter_training.csv\",\n",
    "    header=None,   # IMPORTANT\n",
    "    names=[\"id\", \"topic\", \"label\", \"text\"]\n",
    ")\n",
    "\n",
    "print(df.head())\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd5531ad-80b6-47d0-9183-b5b89a72edea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "Negative    22542\n",
      "Positive    20832\n",
      "Neutral     18318\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df[df['label'] != \"Irrelevant\"]   # remove irrelevant class\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75b26b1d-dba4-4557-9943-39d9e352a1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>i am coming to the borders and i will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>im getting on borderlands and i will kill you all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  im getting on borderlands and i will murder yo...   \n",
       "1  I am coming to the borders and I will kill you...   \n",
       "2  im getting on borderlands and i will kill you ...   \n",
       "3  im coming on borderlands and i will murder you...   \n",
       "4  im getting on borderlands 2 and i will murder ...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  i am coming to the borders and i will kill you...  \n",
       "2  im getting on borderlands and i will kill you all  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands and i will murder yo...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)       # remove links\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)          # remove @mentions\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)      # keep only letters/spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # clean extra spaces\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean)\n",
    "\n",
    "df[['text','clean_text']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3593ca56-0687-4f73-b40f-da05ff55a09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (49353, 5000)\n",
      "Test shape: (12339, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['clean_text'], \n",
    "    df['label'], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create vectorizer (limit features so it's fast)\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit-transform on training data\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform test data\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Train shape:\", X_train_vec.shape)\n",
    "print(\"Test shape:\", X_test_vec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bfe5517-ff97-4bf4-8212-c2ba13e09c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74981765134938\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.79      0.77      0.78      4509\n",
      "     Neutral       0.69      0.71      0.70      3650\n",
      "    Positive       0.76      0.76      0.76      4180\n",
      "\n",
      "    accuracy                           0.75     12339\n",
      "   macro avg       0.75      0.75      0.75     12339\n",
      "weighted avg       0.75      0.75      0.75     12339\n",
      "\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[3465  608  436]\n",
      " [ 475 2606  569]\n",
      " [ 426  573 3181]]\n"
     ]
    }
   ],
   "source": [
    "# Train & evaluate a simple classifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Encode labels to integers\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Train a logistic regression (fast, baseline)\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model.fit(X_train_vec, y_train_enc)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# Eval\n",
    "acc = accuracy_score(y_test_enc, y_pred)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test_enc, y_pred, target_names=le.classes_))\n",
    "\n",
    "print(\"\\nConfusion matrix (rows=true, cols=pred):\")\n",
    "print(confusion_matrix(y_test_enc, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51a76f1d-883e-4fcc-a632-ff6b2d8b81e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and vectorizer to artifacts/\n"
     ]
    }
   ],
   "source": [
    "# Run this in your notebook (where `model` and `vectorizer` already exist)\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "joblib.dump(model, \"artifacts/sentiment_model.joblib\")\n",
    "joblib.dump(vectorizer, \"artifacts/vectorizer.joblib\")\n",
    "\n",
    "print(\"Saved model and vectorizer to artifacts/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d335468-adff-4665-9cef-2e1ab88a9af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
